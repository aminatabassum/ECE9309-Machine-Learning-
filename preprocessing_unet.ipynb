{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPamj8goMExK",
        "outputId": "7bd40542-9303-429c-93a5-d00c427cb346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n",
            "NVIDIA GeForce RTX 2080 SUPER\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should return True if GPU is available\n",
        "print(torch.cuda.device_count())  # Should be > 0 if GPU is accessible\n",
        "print(torch.cuda.get_device_name(0))  # Displays the GPU model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2_PRqrqWJa_",
        "outputId": "500b689c-deff-4c17-d1dc-00d124df5b30"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate,ZeroPadding3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkbDSbpuN58i",
        "outputId": "71ded8c9-79e4-4440-b09c-dbed9ab18adb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10031\n"
          ]
        }
      ],
      "source": [
        "video_path='/content/Echonet/EchoNet-Dynamic/Videos'\n",
        "all_videos=os.listdir(video_path)\n",
        "print(len(all_videos))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ya9m05tJ4Ea",
        "outputId": "f3930f91-9896-45d9-8c0f-681bb967c7cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n"
          ]
        }
      ],
      "source": [
        "#randomly select 50 videos\n",
        "selected_videos=random.sample(all_videos,50)\n",
        "print(len(selected_videos))\n",
        "dest_path='/content/drive/MyDrive/Selected_Videos'\n",
        "os.makedirs(dest_path,exist_ok=True)\n",
        "for video in selected_videos:\n",
        "    shutil.copy(os.path.join(video_path,video),os.path.join(dest_path,video))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2awBvaE3KovF"
      },
      "outputs": [],
      "source": [
        "# extract frames from video and visualize these frames\n",
        "new_video_path='/content/Selected_Videos'\n",
        "def extract_frames(videopath):\n",
        "    cap=cv2.VideoCapture(videopath)\n",
        "    frames=[]\n",
        "    if not cap.isOpened():\n",
        "        print(f'error opening {videopath} ')\n",
        "    while cap.isOpened():\n",
        "        ret,frame=cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "frames_dict={}\n",
        "\n",
        "\n",
        "for video in os.listdir(new_video_path):\n",
        "    frames=extract_frames(os.path.join(new_video_path,video))\n",
        "    frames_dict[video]=frames\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBaGTpyU13tR",
        "outputId": "ad19bd8e-2be6-4cf6-9aef-8bd8dd58070f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n"
          ]
        }
      ],
      "source": [
        "# extract frames from video and visualize these frames\n",
        "new_video_path='Selected_Videos'\n",
        "def extract_frames(videopath,sampling_rate=2):\n",
        "    cap=cv2.VideoCapture(videopath)\n",
        "    frames=[]\n",
        "    frame_count=0\n",
        "    if not cap.isOpened():\n",
        "        print(f'error opening {videopath} ')\n",
        "    while cap.isOpened():\n",
        "        ret,frame=cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_rgb=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if frame_count % sampling_rate == 0:\n",
        "            frames.append(frame_rgb)\n",
        "        frame_count+=1\n",
        "\n",
        "\n",
        "        # gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
        "        # gray=np.expand_dims(gray,axis=-1)\n",
        "        # print(gray.shape)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "frames_dict={}\n",
        "\n",
        "\n",
        "for video in os.listdir(new_video_path):\n",
        "    frames=extract_frames(os.path.join(new_video_path,video))\n",
        "    frames_dict[video]=frames\n",
        "\n",
        "print(len(frames_dict))\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Kt7L0PaHKs_k",
        "outputId": "6e8de2b1-3c45-4208-922c-3279322ba266"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "FileName",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "EF",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "ESV",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "EDV",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "FrameHeight",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "FrameWidth",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "FPS",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "NumberOfFrames",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Split",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "efa6fd14-d855-4b22-aca4-f7fd99f78393",
              "rows": [
                [
                  "0",
                  "0X100009310A3BD7FC",
                  "78.49840597",
                  "14.88136797",
                  "69.21053366",
                  "112",
                  "112",
                  "50",
                  "174",
                  "VAL"
                ],
                [
                  "1",
                  "0X1002E8FBACD08477",
                  "59.10198811",
                  "40.38387624",
                  "98.74288352",
                  "112",
                  "112",
                  "50",
                  "215",
                  "TRAIN"
                ],
                [
                  "2",
                  "0X1005D03EED19C65B",
                  "62.36379841",
                  "14.2677839",
                  "37.90973395",
                  "112",
                  "112",
                  "50",
                  "104",
                  "TRAIN"
                ],
                [
                  "3",
                  "0X10075961BC11C88E",
                  "54.54509675",
                  "33.14308352",
                  "72.91420979",
                  "112",
                  "112",
                  "55",
                  "122",
                  "TRAIN"
                ],
                [
                  "4",
                  "0X10094BA0A028EAC3",
                  "24.88774165",
                  "127.5819446",
                  "169.8550242",
                  "112",
                  "112",
                  "52",
                  "207",
                  "VAL"
                ]
              ],
              "shape": {
                "columns": 9,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FileName</th>\n",
              "      <th>EF</th>\n",
              "      <th>ESV</th>\n",
              "      <th>EDV</th>\n",
              "      <th>FrameHeight</th>\n",
              "      <th>FrameWidth</th>\n",
              "      <th>FPS</th>\n",
              "      <th>NumberOfFrames</th>\n",
              "      <th>Split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0X100009310A3BD7FC</td>\n",
              "      <td>78.498406</td>\n",
              "      <td>14.881368</td>\n",
              "      <td>69.210534</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>50</td>\n",
              "      <td>174</td>\n",
              "      <td>VAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0X1002E8FBACD08477</td>\n",
              "      <td>59.101988</td>\n",
              "      <td>40.383876</td>\n",
              "      <td>98.742884</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>50</td>\n",
              "      <td>215</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0X1005D03EED19C65B</td>\n",
              "      <td>62.363798</td>\n",
              "      <td>14.267784</td>\n",
              "      <td>37.909734</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>50</td>\n",
              "      <td>104</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0X10075961BC11C88E</td>\n",
              "      <td>54.545097</td>\n",
              "      <td>33.143084</td>\n",
              "      <td>72.914210</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>55</td>\n",
              "      <td>122</td>\n",
              "      <td>TRAIN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0X10094BA0A028EAC3</td>\n",
              "      <td>24.887742</td>\n",
              "      <td>127.581945</td>\n",
              "      <td>169.855024</td>\n",
              "      <td>112</td>\n",
              "      <td>112</td>\n",
              "      <td>52</td>\n",
              "      <td>207</td>\n",
              "      <td>VAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             FileName         EF         ESV         EDV  FrameHeight  \\\n",
              "0  0X100009310A3BD7FC  78.498406   14.881368   69.210534          112   \n",
              "1  0X1002E8FBACD08477  59.101988   40.383876   98.742884          112   \n",
              "2  0X1005D03EED19C65B  62.363798   14.267784   37.909734          112   \n",
              "3  0X10075961BC11C88E  54.545097   33.143084   72.914210          112   \n",
              "4  0X10094BA0A028EAC3  24.887742  127.581945  169.855024          112   \n",
              "\n",
              "   FrameWidth  FPS  NumberOfFrames  Split  \n",
              "0         112   50             174    VAL  \n",
              "1         112   50             215  TRAIN  \n",
              "2         112   50             104  TRAIN  \n",
              "3         112   55             122  TRAIN  \n",
              "4         112   52             207    VAL  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# split the data\n",
        "file_list=pd.read_csv('EchoNet-Dynamic/EchoNet-Dynamic/FileList.csv')\n",
        "file_list.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iI0ak_KYK4Al"
      },
      "outputs": [],
      "source": [
        "train_files=file_list[file_list['Split']=='TRAIN']['FileName'].tolist()\n",
        "val_files=file_list[file_list['Split']=='VAL']['FileName'].tolist()\n",
        "test_files=file_list[file_list['Split']=='TEST']['FileName'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QITlaUCoK72F",
        "outputId": "eccac583-b0fc-4af3-ef68-9ee7fa96b66e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7465, 1288, 1277)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_files),len(val_files),len(test_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Vda74MQ-K-oe"
      },
      "outputs": [],
      "source": [
        "train_frames=[frames_dict[f'{file}.avi'] for file in train_files if f'{file}.avi' in frames_dict]\n",
        "val_frames=[frames_dict[f'{file}.avi'] for file in val_files if f'{file}.avi' in frames_dict]\n",
        "test_frames=[frames_dict[f'{file}.avi'] for file in test_files if f'{file}.avi' in frames_dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyImXr3lLBKe",
        "outputId": "8015a59a-da6a-44c8-d832-faf3f2277d08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35, 7, 8)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_frames),len(val_frames),len(test_frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6MXV4K4jLFsu"
      },
      "outputs": [],
      "source": [
        "#create segmentation mask\n",
        "volume_tracings=pd.read_csv('Echonet-Dynamic/EchoNet-Dynamic/VolumeTracings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "djqcIDAnLLW2"
      },
      "outputs": [],
      "source": [
        "def create_mask(image_shape,contour_points):\n",
        "    mask=np.zeros(image_shape,dtype=np.uint8)\n",
        "    contour=np.array(contour_points,dtype=np.int32).reshape(-1,1,2)\n",
        "    cv2.fillPoly(mask,[contour],1)\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z1wn3vsVLN_m"
      },
      "outputs": [],
      "source": [
        "def generate_masks(frames, file_name):\n",
        "    masks = []\n",
        "    for frame_number, frame in enumerate(frames):\n",
        "        # Check if the file and frame exist in volume_tracings\n",
        "        matching_rows = volume_tracings[(volume_tracings['FileName'] == file_name) & (volume_tracings['Frame'] == frame_number)]\n",
        "        if matching_rows.empty:\n",
        "            # Handle the case where there are no matching rows, e.g., skip the frame or create an empty mask\n",
        "            # Here, we create an empty mask\n",
        "            mask = np.zeros(frame.shape, dtype=np.uint8)\n",
        "        else:\n",
        "            contour_points = [(matching_rows[f'X{i}'].values[0],\n",
        "                               matching_rows[f'Y{i}'].values[0])\n",
        "                              for i in range(1, (len(volume_tracings.columns) - 2) // 2 + 1)]\n",
        "            mask = create_mask(frame.shape, contour_points)\n",
        "        masks.append(mask)\n",
        "    return masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8WdGfQALO9W",
        "outputId": "0ac91e76-2689-48f4-c4a4-3d0c3649f5e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35, 50)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_frames),len(frames_dict)\n",
        "#train_masks = [generate_masks(frames, file) for frames, file in zip(train_frames, train_files)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JZxr-fB7Mw0F"
      },
      "outputs": [],
      "source": [
        "train_masks = [generate_masks(frames, file) for frames, file in zip(train_frames, train_files)]\n",
        "val_masks = [generate_masks(frames, file) for frames, file in zip(val_frames, val_files)]\n",
        "test_masks = [generate_masks(frames, file) for frames, file in zip(test_frames, test_files)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "l-L_2itCeSOH"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save train_masks\n",
        "with open('train_masks.pkl', 'wb') as f:\n",
        "    pickle.dump(train_masks, f)\n",
        "\n",
        "# Save val_masks\n",
        "with open('val_masks.pkl', 'wb') as f:\n",
        "    pickle.dump(val_masks, f)\n",
        "\n",
        "# Save test_masks\n",
        "with open('test_masks.pkl', 'wb') as f:\n",
        "    pickle.dump(test_masks, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9QnC1WCydX53"
      },
      "outputs": [],
      "source": [
        "#preprocess it\n",
        "\n",
        "def normalize_frames(frames):\n",
        "    nf=[frame/255.0 for frame in frames]\n",
        "    return nf\n",
        "\n",
        "def resize(frames,size=(112,112)):\n",
        "    nr=[cv2.resize(frame,size) for frame in frames]\n",
        "    return nr\n",
        "\n",
        "def pad_or_truncate(frames, max_frames=250):\n",
        "    if len(frames) > max_frames:\n",
        "        return frames[:max_frames]\n",
        "    else:\n",
        "        return frames + [frames[-1]] * (max_frames - len(frames))\n",
        "\n",
        "def preprocess(frames,masks):\n",
        "    rf=resize(frames)\n",
        "    nf=normalize_frames(rf)\n",
        "    pt=pad_or_truncate(nf)\n",
        "\n",
        "    rm=resize(masks)\n",
        "    nm=normalize_frames(rm)\n",
        "    ptm=pad_or_truncate(nm)\n",
        "\n",
        "    return pt ,ptm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7dpLMS-dfb2Q"
      },
      "outputs": [],
      "source": [
        "preprocessed_train = [preprocess(frames, masks) for frames, masks in zip(train_frames, train_masks)]\n",
        "preprocessed_val = [preprocess(frames, masks) for frames, masks in zip(val_frames, val_masks)]\n",
        "preprocessed_test = [preprocess(frames, masks) for frames, masks in zip(test_frames, test_masks)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ee0XyATehp5M"
      },
      "outputs": [],
      "source": [
        "prerocessed_train_frames, preprocessed_train_masks = zip(*preprocessed_train)\n",
        "prerocessed_val_frames, preprocessed_val_masks = zip(*preprocessed_val)\n",
        "prerocessed_test_frames, preprocessed_test_masks = zip(*preprocessed_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3W_O2cehtFc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def unet_model(input_size=(250,112, 112, 3)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv3D(64,(3,3,3) , activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv3D(64, (3,3,3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling3D(pool_size=(2,2,2))(conv1)\n",
        "\n",
        "    conv2 = Conv3D(128, (3,3,3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv3D(128, (3,3,3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling3D(pool_size=(2,2,2))(conv2)\n",
        "\n",
        "    conv3 = Conv3D(256,(3,3,3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv3D(256, (3,3,3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling3D(pool_size=(2,2,2))(conv3)\n",
        "\n",
        "    conv4 = Conv3D(512, (3,3,3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv3D(512, (3,3,3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling3D(pool_size=(2,2,2))(conv4)\n",
        "\n",
        "    conv5 = Conv3D(1024, (3,3,3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv3D(1024, (3,3,3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = UpSampling3D(size=(2,2,2))(conv5)\n",
        "    pad_up6 = ZeroPadding3D(((0, 1), (0, 0), (0, 0)))(up6)\n",
        "    merge6 = concatenate([conv4, pad_up6], axis=4)\n",
        "    conv6 = Conv3D(512,(3,3,3), activation='relu', padding='same')(merge6)\n",
        "    conv6 = Conv3D(512, (3,3,3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = UpSampling3D(size=(2,2,2))(conv6)\n",
        "    merge7 = concatenate([conv3, up7], axis=4)\n",
        "    conv7 = Conv3D(256, (3,3,3), activation='relu', padding='same')(merge7)\n",
        "    conv7 = Conv3D(256, (3,3,3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = UpSampling3D(size=(2,2, 2))(conv7)\n",
        "    pad_up8 = ZeroPadding3D(((0, 1), (0, 0), (0, 0)))(up8)\n",
        "    merge8 = concatenate([conv2, pad_up8], axis=4)\n",
        "    conv8 = Conv3D(128, (3,3,3), activation='relu', padding='same')(merge8)\n",
        "    conv8 = Conv3D(128, (3,3,3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = UpSampling3D(size=(2,2,2))(conv8)\n",
        "    merge9 = concatenate([conv1, up9], axis=4)\n",
        "    conv9 = Conv3D(64, (3,3,3), activation='relu', padding='same')(merge9)\n",
        "    conv9 = Conv3D(64, (3,3,3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv3D(1, (1,1,1), activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs, conv10)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = unet_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, y_train = zip(*preprocessed_train)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35, 250, 112, 112, 3)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35, 250, 112, 112, 1)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train = np.mean(y_train, axis=-1, keepdims=True)\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(35, 250, 112, 112, 3)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_KBIQgbahu9U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node functional_1/concatenate_3_1/concat defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\atabass4\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"c:\\Users\\atabass4\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"c:\\Users\\atabass4\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\atabass4\\AppData\\Local\\Temp\\ipykernel_5532\\3989123092.py\", line 5, in <module>\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 368, in fit\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 216, in function\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 129, in multi_step_on_iterator\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 110, in one_step_on_data\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 56, in train_step\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 899, in __call__\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 182, in call\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 632, in call\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 899, in __call__\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\layers\\merging\\base_merge.py\", line 226, in call\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\layers\\merging\\concatenate.py\", line 103, in _merge_function\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 1640, in concatenate\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 966, in concatenate\n\nOOM when allocating tensor with shape[8,250,112,112,192] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node functional_1/concatenate_3_1/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_15443]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[41], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m clear_session()  \u001b[38;5;66;03m# Clear any existing TensorFlow graph\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m unet_model()  \u001b[38;5;66;03m# Redefine the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\atabass4\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node functional_1/concatenate_3_1/concat defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n\n  File \"c:\\Users\\atabass4\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n\n  File \"c:\\Users\\atabass4\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n\n  File \"c:\\Users\\atabass4\\Lib\\asyncio\\events.py\", line 88, in _run\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"C:\\Users\\atabass4\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n\n  File \"C:\\Users\\atabass4\\AppData\\Local\\Temp\\ipykernel_5532\\3989123092.py\", line 5, in <module>\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 368, in fit\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 216, in function\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 129, in multi_step_on_iterator\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 110, in one_step_on_data\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 56, in train_step\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 899, in __call__\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 182, in call\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 171, in _run_through_graph\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 632, in call\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 899, in __call__\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 46, in __call__\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\layers\\merging\\base_merge.py\", line 226, in call\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\layers\\merging\\concatenate.py\", line 103, in _merge_function\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\", line 1640, in concatenate\n\n  File \"c:\\Users\\atabass4\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\", line 966, in concatenate\n\nOOM when allocating tensor with shape[8,250,112,112,192] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node functional_1/concatenate_3_1/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_15443]"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.backend import clear_session\n",
        "\n",
        "clear_session()  # Clear any existing TensorFlow graph\n",
        "model = unet_model()  # Redefine the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=8, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8oerx6qh-ys"
      },
      "outputs": [],
      "source": [
        "X_val, y_val = zip(*preprocessed_val)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "\n",
        "X_test, y_test = zip(*preprocessed_test)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTCPo1N5iElE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize a sample prediction\n",
        "sample_index = 0\n",
        "predicted_mask = model.predict(np.expand_dims(X_test[sample_index], axis=0))[0]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Original Frame\")\n",
        "plt.imshow(X_test[sample_index], cmap='gray')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"Ground Truth Mask\")\n",
        "plt.imshow(y_test[sample_index], cmap='gray')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Predicted Mask\")\n",
        "plt.imshow(predicted_mask, cmap='gray')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVMR0FFwQmHg"
      },
      "outputs": [],
      "source": [
        "#loop to iterate through folder to check frame size for all videos and fps\n",
        "for v in os.listdir(video_path):\n",
        "    if v.endswith('.avi'):\n",
        "        path=os.path.join(video_path,v)\n",
        "        w,h,c,fps=get_frame_size(path)\n",
        "        print(f'frame size is {w}x{h} and count is {c} with fps equals {fps}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwotPdhAQ54a"
      },
      "outputs": [],
      "source": [
        "# extract frames from video and visualize these frames\n",
        "def extract_frames(videopath):\n",
        "    cap=cv2.VideoCapture(videopath)\n",
        "    frames=[]\n",
        "    if not cap.isOpened():\n",
        "        print('error')\n",
        "    while True:\n",
        "        ret,frame=cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        #frame=cv2.resize(frame,(112,112))\n",
        "        frames.append(frame)\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtX4sqNGKz5Y"
      },
      "outputs": [],
      "source": [
        "video_path='/content/Echonet/EchoNet-Dynamic/Videos'\n",
        "frames_dict={}\n",
        "for v in os.listdir(video_path):\n",
        "  path=os.path.join(video_path,v)\n",
        "  frames=extract_frames(path)\n",
        "  frames_dict[v]=frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muLNUuTRRC-T"
      },
      "outputs": [],
      "source": [
        "# function to visualize all frames\n",
        "def visualizeframes(frames,framesperrow):\n",
        "    num_frames=len(frames)\n",
        "    num_rows = math.ceil(num_frames /framesperrow)\n",
        "    fig, axes = plt.subplots(num_rows, framesperrow, figsize=(20, num_rows * 4))\n",
        "    axes = axes.flatten()\n",
        "    for i,frame in enumerate(frames):\n",
        "        axes[i].imshow(frame)\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# visualizeframes(f,5)\n",
        "#print('total number of frames in this video is :', len(f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUn357FcRG8r"
      },
      "outputs": [],
      "source": [
        "# to play multiple videos in a folder\n",
        "flag=0\n",
        "def play_video(video_path):\n",
        "    global flag\n",
        "    cap=cv2.VideoCapture(video_path)\n",
        "    cv2.namedWindow('Video',cv2.WINDOW_NORMAL)\n",
        "    cv2.resizeWindow('Video',800,600)\n",
        "    while cap.isOpened():\n",
        "        ret,frame=cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        cv2.imshow('Video',frame)\n",
        "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "            flag=1\n",
        "            break\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M6M0CqCCr-G"
      },
      "outputs": [],
      "source": [
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za1MKEeURNhy"
      },
      "outputs": [],
      "source": [
        "#loop to iterate through folder\n",
        "for v in os.listdir(video_path):\n",
        "    if v.endswith('.avi'):\n",
        "        path=os.path.join(video_path,v)\n",
        "        if flag==0:\n",
        "            print(f'playing {v}')\n",
        "            play_video(path)\n",
        "        else:\n",
        "            print('interrupted')\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG0-lTuCRSDh"
      },
      "outputs": [],
      "source": [
        "#loop to iterate through folder\n",
        "# this block of code iterates through all vides, extracts frames, normalizes those frames and performs padding or truncation to make sure all videos have same number of frames\n",
        "# These frames are stored in list and then converted to an array to be used as input for model.\n",
        "os.makedirs('training',exist_ok=True)\n",
        "os.makedirs('testing',exist_ok=True)\n",
        "os.makedirs('validation',exist_ok=True)\n",
        "df=pd.read_csv('/content/Echonet/EchoNet-Dynamic/FileList.csv')\n",
        "pad_trunc=[]\n",
        "for v in os.listdir(video_path):\n",
        "    if v.endswith('.avi'):\n",
        "        path=os.path.join(video_path,v)\n",
        "        frames=extract_frames(path)\n",
        "        normalized=normalize_frames(frames)\n",
        "        padtruncframes=pad_or_truncate(normalized)\n",
        "        print(f'number of frames in {path} is {len(padtruncframes)}')\n",
        "    pad_trunc.append(padtruncframes)\n",
        "    print(len(pad_trunc))\n",
        "\n",
        "    # split files into training, testing and validation\n",
        "    file_name=os.path.splitext(v)[0]\n",
        "    split_type=df.loc[df['FileName']==file_name,'Split'].values[0]\n",
        "\n",
        "    if split_type=='TRAIN':\n",
        "        shutil.move(f'{path}',f'training/{file_name}.avi')\n",
        "    elif split_type == 'TEST':\n",
        "        shutil.move(f'{path}',f'testing/{file_name}.avi')\n",
        "    elif split_type == 'VAL':\n",
        "        shutil.move(f'{path}',f'validation/{file_name}.avi')\n",
        "\n",
        "    print('files have been successfully split')\n",
        "\n",
        "        #w,h,c,fps=get_frame_size(path)\n",
        "        #print(f'frame size is {w}x{h} and count is {c} with fps equals {fps}')\n",
        "# saving list of processed frames in numpy array to use in model\n",
        "padtruncarray=np.array(pad_trunc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH5rXogSR8fC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXnQQjlHXCly"
      },
      "outputs": [],
      "source": [
        "volume_tracings=pd.read_csv('/content/Echonet/EchoNet-Dynamic/VolumeTracings.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
